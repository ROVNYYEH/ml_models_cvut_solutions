{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 1 - redukce dimenzionality a binární klasifikace\n",
    "\n",
    "  * **Deadline je 22. 4. 2024, 23:59:59**, pokud odevzdáte úkol do 29. 4. 2024, 23:59:59, budete penalizování -12 body, pozdější odevzdání je bez bodu.\n",
    "  * V rámci tohoto úkolu se musíte vypořádat s vysokou dimenzí problému a poté úspěšně aplikovat vhodný klasfikační model.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "Využívejte buňky typu `Markdown` k vysvětlování Vašeho postupu. Za nepřehlednost budou strhávány body.\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    " * Zdrojem dat jsou soubory `train.csv` a `evaluate.csv`.\n",
    " * Jedná se o obrázky 28x28 pixelů ve stupních šedi, které byly získány z [Fashion Mnist datasetu](https://www.kaggle.com/datasets/zalando-research/fashionmnist).\n",
    " * Soubor `train.csv` obsahuje trénovací data.\n",
    " * Cílová (vysvětlovaná) proměnná se jmenuje **label**.\n",
    " * Soubor `evaluate.csv` obsahuje testovací data bez hodnot skutečných labelů.\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Body zadání**, za jejichž (poctivé) vypracování získáte **25 bodů**:\n",
    "  * V notebooku načtěte data ze souboru `train.csv`. Vhodným způsobem si je rozdělte na podmnožiny, které Vám poslouží pro trénování, porovnávání modelů a následnou predikci výkonnosti finálního modelu.\n",
    "  * Proveďte základní průzkum dat a svá pozorování diskutujte. Některé obrázky také zobrazte.\n",
    "  * Postupně aplikujte modely **SVM**, **naivní Bayesův klasifikátor** a **LDA**, přičemž pro každý z nich:\n",
    "      * Okomentujte vhodnost daného modelu pro daný typ úlohy.\n",
    "      * Vyberte si hlavní hyperparametry k ladění (pokud model má hyperparametry) a najděte jejich nejlepší hodnoty.\n",
    "      * Experimentujte se standardizací/normalizací dat.\n",
    "      * U SVM vyzkoušejte alespoň dvě různé jádrové funkce.\n",
    "      * Získané výsledky vždy řádně okomentujte.\n",
    "\n",
    "\n",
    "  * Postupně aplikujte metody redukce dimenzionality PCA a LLE, přičemž pro každou z nich: \n",
    "      * Zopakujte předchozí kroky a pokuste modely vylepšit\n",
    "      * Zkoumejte jaká dimenze je z hlediska výkonnosti finálního modelu nejlepší.\n",
    "      * Získané výsledky vždy řádně okomentujte.\n",
    "    \n",
    "  * Ze všech zkoušených možností vyberte finální model a odhadněte, jakou přesnost můžete očekávat na nových datech, která jste doposud neměli k dispozici.\n",
    "  \n",
    "  * Nakonec načtěte vyhodnocovací data ze souboru`evaluate.csv`. Pomocí finálního modelu napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte soubor `results.csv`, ve kterém získané predikce uložíte do sloupce **label** a identifikátory do sloupce **ID**. Tento soubor též odevzdejte (uložte do projektu vedle notebooku).\n",
    "   \n",
    "   * Ukázka prvních řádků souboru `results.csv`:\n",
    "  \n",
    "```\n",
    "ID,label\n",
    "0,0\n",
    "1,1\n",
    "...\n",
    "```\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-ML2/homeworks/index.html.\n",
    "  * Vytvořte i csv soubor `results.csv` s predikcemi a uložte ho v rámci projektu vedle ipython notebooku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "### odtud už je to Vaše\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 14.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>103</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       1       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       1       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       1       0       0       0       0       0       0       0       0   \n",
       "5       1       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       1       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "10      1       0       0       0       0       0       0       0       1   \n",
       "11      0       0       0       0       0       0       0       0       0   \n",
       "12      1       0       0       0       0       0       0       0       0   \n",
       "13      1       0       0       0       0       0       0       0       0   \n",
       "14      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0        0  ...       208       122         0         0         0         0   \n",
       "1        0  ...         0         0         0         0         0         0   \n",
       "2        1  ...        75        11         0         1         0         0   \n",
       "3        0  ...       106       103        76         0         0         0   \n",
       "4        0  ...         0         0         0         0         0         0   \n",
       "5        0  ...         0         0         0         0         0         0   \n",
       "6        0  ...        81         0         0         0         0         0   \n",
       "7        0  ...       157       120         0         0         0         0   \n",
       "8        9  ...        98         6         0         0         0         0   \n",
       "9        0  ...         0         0         0         0         0         0   \n",
       "10       0  ...        44        23         0         0         0         0   \n",
       "11       2  ...        98         0         0         0         0         0   \n",
       "12       0  ...         0         0         0         0         0         0   \n",
       "13       0  ...         0         0         0         0         0         0   \n",
       "14       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "    pixel781  pixel782  pixel783  pixel784  \n",
       "0          0         0         0         0  \n",
       "1          0         0         0         0  \n",
       "2          0         0         0         0  \n",
       "3          0         0         0         0  \n",
       "4          0         0         0         0  \n",
       "5          0         0         0         0  \n",
       "6          0         0         0         0  \n",
       "7          0         0         0         0  \n",
       "8          0         0         0         0  \n",
       "9          0         0         0         0  \n",
       "10         0         0         0         0  \n",
       "11         0         0         0         0  \n",
       "12         0         0         0         0  \n",
       "13         0         0         0         0  \n",
       "14         0         0         0         0  \n",
       "\n",
       "[15 rows x 785 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "           ..\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "pixel784    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization:\n",
    "To better understand the data, it is useful to visualize multiple images. You can use the matplotlib library to display images from the data. Here is some sample code that will show the first few images and their labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function for displaying the image\n",
    "def plot_image(data, index):\n",
    "    plt.imshow(data.iloc[index, 1:].values.reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Label: {data.iloc[index, 0]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# Display the first 5 images\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plot_image(df, i)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data normalization:\n",
    "If the pixel values are not normalized (i.e., range from 0 to 255), it may be useful to normalize the data to improve the performance of machine learning models. Normalization can be done by dividing the pixel values by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 1:] = df.iloc[:, 1:] / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)  # 60 / 40\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 40 -> 20/20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.9645833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       250\n",
      "           1       0.96      0.97      0.96       230\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialization of SVM model with linear kernel\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting labels on the validation set\n",
    "y_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Model estimation\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Classification accuracy: {accuracy}\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the SVM model with linear kernel in this case is high for both classes, as evidenced by the near-perfect values of all metrics. \n",
    "\n",
    "    Linear separability of the data:\n",
    "        Since the SVM with linear kernel performed well, it can be assumed that the features separate the two classes reasonably well in linear space.\n",
    "    Data quality:\n",
    "        High values of the metrics can also indicate low noise and well scaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear, Validation Accuracy: 0.9645833333333333\n",
      "Kernel: linear, Test Accuracy: 0.9645833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       248\n",
      "           1       0.97      0.95      0.96       232\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.97      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "Kernel: poly, Validation Accuracy: 0.96875\n",
      "Kernel: poly, Test Accuracy: 0.96875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       248\n",
      "           1       0.95      0.98      0.97       232\n",
      "\n",
      "    accuracy                           0.97       480\n",
      "   macro avg       0.97      0.97      0.97       480\n",
      "weighted avg       0.97      0.97      0.97       480\n",
      "\n",
      "Kernel: rbf, Validation Accuracy: 0.96875\n",
      "Kernel: rbf, Test Accuracy: 0.9729166666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       248\n",
      "           1       0.95      0.99      0.97       232\n",
      "\n",
      "    accuracy                           0.97       480\n",
      "   macro avg       0.97      0.97      0.97       480\n",
      "weighted avg       0.97      0.97      0.97       480\n",
      "\n",
      "Kernel: sigmoid, Validation Accuracy: 0.7166666666666667\n",
      "Kernel: sigmoid, Test Accuracy: 0.675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70       248\n",
      "           1       0.68      0.62      0.65       232\n",
      "\n",
      "    accuracy                           0.68       480\n",
      "   macro avg       0.68      0.67      0.67       480\n",
      "weighted avg       0.68      0.68      0.67       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_svm_kernel(kernel_type, **kwargs):\n",
    "    model = SVC(kernel=kernel_type, **kwargs, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"Kernel: {kernel_type}, Validation Accuracy: {accuracy_score(y_val, y_pred)}\")\n",
    "    print(f\"Kernel: {kernel_type}, Test Accuracy: {test_accuracy}\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "test_svm_kernel('linear')\n",
    "test_svm_kernel('poly', degree=3)\n",
    "test_svm_kernel('rbf')\n",
    "test_svm_kernel('sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall analysis:\n",
    "\n",
    "    The linear, polynomial and RBF kernels perform very well on both the validation and test dataset, with an accuracy of about 97%. This indicates that the data lends itself well to linear and nonlinear separability.\n",
    "    The sigmoidal kernel lags significantly behind in performance, with an accuracy of about 68%. This may be due to the fact that the sigmoidal kernel transforms the feature space in such a way that class separation becomes less efficient for a given dataset.\n",
    "\n",
    "Detailed analysis by kernel:\n",
    "\n",
    "    Linear kernel:\n",
    "        Very high precision and balanced precision and recall values for both classes. Excellent for data where classes are linearly separable.\n",
    "\n",
    "    Polynomial kernel (degree 3):\n",
    "        Similar performance to the linear kernel, with slightly lower precision on the validation set, but the same on the test set. The polynomial kernel can capture more complex relationships between features.\n",
    "\n",
    "    RBF kernel:\n",
    "        Similar results with the polynomial kernel, good for modeling complex separations in feature space. Effective in the presence of nonlinear relationships between features and classes.\n",
    "\n",
    "    Sigmoidal kernel:\n",
    "        Significantly worse performance. The sigmoidal kernel can behave erratically, especially if the data does not have a clear probability partitioning similar to logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV 1/3] END ........C=0.1, gamma=1, kernel=rbf;, score=0.512 total time=   0.9s\n",
      "[CV 2/3] END ........C=0.1, gamma=1, kernel=rbf;, score=0.515 total time=   0.7s\n",
      "[CV 3/3] END ........C=0.1, gamma=1, kernel=rbf;, score=0.515 total time=   0.9s\n",
      "[CV 1/3] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.877 total time=   0.6s\n",
      "[CV 2/3] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.890 total time=   0.6s\n",
      "[CV 3/3] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.860 total time=   0.5s\n",
      "[CV 1/3] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.954 total time=   0.3s\n",
      "[CV 2/3] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.948 total time=   0.3s\n",
      "[CV 3/3] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.956 total time=   0.3s\n",
      "[CV 1/3] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.940 total time=   0.7s\n",
      "[CV 2/3] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.931 total time=   0.5s\n",
      "[CV 3/3] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.940 total time=   0.5s\n",
      "[CV 1/3] END ..........C=1, gamma=1, kernel=rbf;, score=0.515 total time=   0.6s\n",
      "[CV 2/3] END ..........C=1, gamma=1, kernel=rbf;, score=0.515 total time=   0.6s\n",
      "[CV 3/3] END ..........C=1, gamma=1, kernel=rbf;, score=0.517 total time=   0.6s\n",
      "[CV 1/3] END ........C=1, gamma=0.1, kernel=rbf;, score=0.960 total time=   0.4s\n",
      "[CV 2/3] END ........C=1, gamma=0.1, kernel=rbf;, score=0.948 total time=   0.4s\n",
      "[CV 3/3] END ........C=1, gamma=0.1, kernel=rbf;, score=0.952 total time=   0.4s\n",
      "[CV 1/3] END .......C=1, gamma=0.01, kernel=rbf;, score=0.971 total time=   0.1s\n",
      "[CV 2/3] END .......C=1, gamma=0.01, kernel=rbf;, score=0.969 total time=   0.1s\n",
      "[CV 3/3] END .......C=1, gamma=0.01, kernel=rbf;, score=0.981 total time=   0.1s\n",
      "[CV 1/3] END ......C=1, gamma=0.001, kernel=rbf;, score=0.969 total time=   0.2s\n",
      "[CV 2/3] END ......C=1, gamma=0.001, kernel=rbf;, score=0.958 total time=   0.2s\n",
      "[CV 3/3] END ......C=1, gamma=0.001, kernel=rbf;, score=0.965 total time=   0.2s\n",
      "[CV 1/3] END .........C=10, gamma=1, kernel=rbf;, score=0.517 total time=   0.7s\n",
      "[CV 2/3] END .........C=10, gamma=1, kernel=rbf;, score=0.515 total time=   0.6s\n",
      "[CV 3/3] END .........C=10, gamma=1, kernel=rbf;, score=0.519 total time=   0.6s\n",
      "[CV 1/3] END .......C=10, gamma=0.1, kernel=rbf;, score=0.963 total time=   0.4s\n",
      "[CV 2/3] END .......C=10, gamma=0.1, kernel=rbf;, score=0.952 total time=   0.4s\n",
      "[CV 3/3] END .......C=10, gamma=0.1, kernel=rbf;, score=0.956 total time=   0.4s\n",
      "[CV 1/3] END ......C=10, gamma=0.01, kernel=rbf;, score=0.977 total time=   0.1s\n",
      "[CV 2/3] END ......C=10, gamma=0.01, kernel=rbf;, score=0.973 total time=   0.1s\n",
      "[CV 3/3] END ......C=10, gamma=0.01, kernel=rbf;, score=0.979 total time=   0.1s\n",
      "[CV 1/3] END .....C=10, gamma=0.001, kernel=rbf;, score=0.977 total time=   0.1s\n",
      "[CV 2/3] END .....C=10, gamma=0.001, kernel=rbf;, score=0.967 total time=   0.1s\n",
      "[CV 3/3] END .....C=10, gamma=0.001, kernel=rbf;, score=0.977 total time=   0.1s\n",
      "[CV 1/3] END ........C=100, gamma=1, kernel=rbf;, score=0.517 total time=   0.6s\n",
      "[CV 2/3] END ........C=100, gamma=1, kernel=rbf;, score=0.515 total time=   0.6s\n",
      "[CV 3/3] END ........C=100, gamma=1, kernel=rbf;, score=0.519 total time=   0.6s\n",
      "[CV 1/3] END ......C=100, gamma=0.1, kernel=rbf;, score=0.963 total time=   0.4s\n",
      "[CV 2/3] END ......C=100, gamma=0.1, kernel=rbf;, score=0.952 total time=   0.4s\n",
      "[CV 3/3] END ......C=100, gamma=0.1, kernel=rbf;, score=0.956 total time=   0.7s\n",
      "[CV 1/3] END .....C=100, gamma=0.01, kernel=rbf;, score=0.977 total time=   0.1s\n",
      "[CV 2/3] END .....C=100, gamma=0.01, kernel=rbf;, score=0.971 total time=   0.1s\n",
      "[CV 3/3] END .....C=100, gamma=0.01, kernel=rbf;, score=0.977 total time=   0.1s\n",
      "[CV 1/3] END ....C=100, gamma=0.001, kernel=rbf;, score=0.973 total time=   0.0s\n",
      "[CV 2/3] END ....C=100, gamma=0.001, kernel=rbf;, score=0.967 total time=   0.1s\n",
      "[CV 3/3] END ....C=100, gamma=0.001, kernel=rbf;, score=0.983 total time=   0.1s\n",
      "Best parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Accuracy on validation set: 0.9770833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       250\n",
      "           1       0.97      0.99      0.98       230\n",
      "\n",
      "    accuracy                           0.98       480\n",
      "   macro avg       0.98      0.98      0.98       480\n",
      "weighted avg       0.98      0.98      0.98       480\n",
      "\n",
      "Accuracy on test set: 0.9708333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       248\n",
      "           1       0.97      0.97      0.97       232\n",
      "\n",
      "    accuracy                           0.97       480\n",
      "   macro avg       0.97      0.97      0.97       480\n",
      "weighted avg       0.97      0.97      0.97       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters for Grid Search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Create SVM model\n",
    "svm = SVC()\n",
    "\n",
    "# Customize GridSearchCV\n",
    "grid_search = GridSearchCV(svm, param_grid, refit=True, verbose=3, cv=3)\n",
    "\n",
    "# Train the model on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "print(\"Accuracy on validation set:\", accuracy_score(y_val, y_pred_val))\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter estimation and results:\n",
    "\n",
    "    Best model parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}. These parameters indicate that a relatively high level of regularization (C=10) and an average value of the 'gamma' parameter are best suited for the data, helping to strike a balance between capturing data complexity and avoiding overfitting.\n",
    "\n",
    "Performance on the validation set:\n",
    "\n",
    "    Accuracy: 97.71%. This is an excellent result showing that SVM performs well in classification on the data.\n",
    "    Precision and recall: Both are close to 98% for both classes, indicating that the model does an excellent job distinguishing between the two classes, minimizing both false positives and false negatives.\n",
    "\n",
    "Performance on the test set:\n",
    "\n",
    "    Accuracy: 97.08%. This confirms that the model generalizes well to the results obtained on the validation set, also on the new data.\n",
    "    Precision and recall: Again show excellent results comparable to the validation set, confirming the robustness of the model to overfitting.\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "    Performance of SVM with RBF kernel: The data is well processed using this kernel configuration, as evidenced by the high precision and balanced values of the other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive Bayesian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of naive Bayesian classifier on validation set: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       250\n",
      "           1       0.92      0.98      0.95       230\n",
      "\n",
      "    accuracy                           0.95       480\n",
      "   macro avg       0.95      0.95      0.95       480\n",
      "weighted avg       0.95      0.95      0.95       480\n",
      "\n",
      "Accuracy of naive Bayesian classifier on test set: 0.9395833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       248\n",
      "           1       0.91      0.97      0.94       232\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.94      0.94      0.94       480\n",
      "weighted avg       0.94      0.94      0.94       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a naive Bayesian model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Training the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_val = nb_model.predict(X_val)\n",
    "print(\"Accuracy of naive Bayesian classifier on validation set:\", accuracy_score(y_val, y_pred_val))\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = nb_model.predict(X_test)\n",
    "print(\"Accuracy of naive Bayesian classifier on test set:\", accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of results on validation set:\n",
    "\n",
    "    Precision: 95%. This is an excellent result for a naive Bayesian, especially given his assumptions about feature independence.\n",
    "    Precision and Recall:\n",
    "        Class 0: High precision (precision) 98% and slightly lower completeness (recall) 92%, indicating that the model is very accurate in identifying class 0 instances but misses some of them.\n",
    "        Class 1: Slightly lower precision of 92% with high completeness of 98%, indicating that the model is less likely to be wrong when predicting class 1, but sometimes misclassifies some other objects as class 1.\n",
    "\n",
    "Analyzing the results on the test set:\n",
    "\n",
    "    Precision: Almost 94%, which shows the good generalization ability of the model and is consistent with the results on the validation set.\n",
    "    Precision and Recall for the test set are similar to the validation set, maintaining consistency in performance between the validation and testing phases.\n",
    "        Class 0: Precision 97% and Recall 92%, similar to the results on the validation set.\n",
    "        Class 1: Precision 91% and Recall 97%, which is also very close to the validation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian model + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the naive Bayesian classifier after PCA on the validation set: 0.8270833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       250\n",
      "           1       0.88      0.73      0.80       230\n",
      "\n",
      "    accuracy                           0.83       480\n",
      "   macro avg       0.84      0.82      0.82       480\n",
      "weighted avg       0.83      0.83      0.83       480\n",
      "\n",
      "Accuracy of the naive Bayesian classifier after PCA on the test set: 0.8166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       248\n",
      "           1       0.86      0.74      0.80       232\n",
      "\n",
      "    accuracy                           0.82       480\n",
      "   macro avg       0.82      0.81      0.81       480\n",
      "weighted avg       0.82      0.82      0.82       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a PCA model that retains 95% of the information\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "nb_model_pca = GaussianNB()\n",
    "nb_model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_nb_pca_val = nb_model_pca.predict(X_val_pca)\n",
    "accuracy_nb_pca_val = accuracy_score(y_val, y_pred_nb_pca_val)\n",
    "print(\"Accuracy of the naive Bayesian classifier after PCA on the validation set:\", accuracy_nb_pca_val)\n",
    "print(classification_report(y_val, y_pred_nb_pca_val))\n",
    "\n",
    "y_pred_nb_pca_test = nb_model_pca.predict(X_test_pca)\n",
    "accuracy_nb_pca_test = accuracy_score(y_test, y_pred_nb_pca_test)\n",
    "print(\"Accuracy of the naive Bayesian classifier after PCA on the test set:\", accuracy_nb_pca_test)\n",
    "print(classification_report(y_test, y_pred_nb_pca_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance analysis after PCA:\n",
    "\n",
    "    Accuracy on the validation set: 82.71%. This is a decrease compared to the results of naive Bayes without PCA, which may be due to the loss of important information in the dimensionality reduction process.\n",
    "    Accuracy on the test set: 81.67%. The model seems to be quite stable between the validation and test sets, but the overall performance has decreased.\n",
    "\n",
    "Detailed analysis of the metrics by class:\n",
    "\n",
    "    Class 0 (validation set): High completeness (91%) indicates that the model defines this class well, but lower accuracy (79%) indicates that many objects of a different class are misclassified as class 0.\n",
    "    Class 1 (validation set): Lower completeness (73%) and higher accuracy (88%), which means that the model is more conservative in defining this class, missing some correct objects.\n",
    "\n",
    "A similar pattern is observed on the test set:\n",
    "\n",
    "    Class 0: Completeness (89%) is higher than on the validation set, which is good for class definition, but accuracy (78%) still indicates misclassification problems.\n",
    "    Class 1: Completeness (74%) and accuracy (86%) are similar to the validation results.\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "    Effectiveness of PCA: The use of PCA can be useful to reduce noise and speed up computation, but in this case it resulted in the loss of important data, reducing the overall performance of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on validation set: 0.9104166666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       250\n",
      "           1       0.94      0.87      0.90       230\n",
      "\n",
      "    accuracy                           0.91       480\n",
      "   macro avg       0.91      0.91      0.91       480\n",
      "weighted avg       0.91      0.91      0.91       480\n",
      "\n",
      "Classification accuracy on test set: 0.9479166666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       248\n",
      "           1       0.97      0.92      0.94       232\n",
      "\n",
      "    accuracy                           0.95       480\n",
      "   macro avg       0.95      0.95      0.95       480\n",
      "weighted avg       0.95      0.95      0.95       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialization and training of LDA\n",
    "lda_classifier = LDA()\n",
    "lda_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_val = lda_classifier.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(\"Classification accuracy on validation set:\", accuracy_val)\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = lda_classifier.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Classification accuracy on test set:\", accuracy_test)\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of results on validation set:\n",
    "\n",
    "    Accuracy: 91.04%. This is a fairly high accuracy, indicating the good ability of LDA to separate classes in the reduced dimensionality space.\n",
    "    Precision and Recall:\n",
    "        Class 0: A high recall (95%) indicates that the model identifies this class well, but with a precision of 89% there are some false positives.\n",
    "        Class 1: Slightly lower recall (87%) with high precision (94%), indicating that there are fewer false positive errors when classifying the second class.\n",
    "\n",
    "Analyzing the results on the test set:\n",
    "\n",
    "    Precision: 94.79%. This is an improvement over the validation set, indicating that the generalization ability of the model is high.\n",
    "    Precision and Recall:\n",
    "        Class 0: Improved precision (precision 93%) and recall (97%), showing an improvement in the ability to correctly identify and minimize errors for this class.\n",
    "        Class 1: Excellent precision (97%) with slightly lower recall (92%), highlighting the model's good ability to recognize class 1 with minimal false positives.\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "    The performance of LDA shows that the method is well suited to the task, especially in terms of creating a clear separation between classes.\n",
    "    Generalizability: The stability of the results between the validation and test sets indicates that the model is not susceptible to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear, Validation Accuracy: 0.9625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       250\n",
      "           1       0.95      0.97      0.96       230\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "Kernel: linear, Test Accuracy: 0.9625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       248\n",
      "           1       0.96      0.96      0.96       232\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "Kernel: poly, Validation Accuracy: 0.9770833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       250\n",
      "           1       0.96      0.99      0.98       230\n",
      "\n",
      "    accuracy                           0.98       480\n",
      "   macro avg       0.98      0.98      0.98       480\n",
      "weighted avg       0.98      0.98      0.98       480\n",
      "\n",
      "Kernel: poly, Test Accuracy: 0.9770833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       248\n",
      "           1       0.97      0.98      0.98       232\n",
      "\n",
      "    accuracy                           0.98       480\n",
      "   macro avg       0.98      0.98      0.98       480\n",
      "weighted avg       0.98      0.98      0.98       480\n",
      "\n",
      "Kernel: rbf, Validation Accuracy: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       250\n",
      "           1       0.95      1.00      0.97       230\n",
      "\n",
      "    accuracy                           0.97       480\n",
      "   macro avg       0.98      0.98      0.97       480\n",
      "weighted avg       0.98      0.97      0.98       480\n",
      "\n",
      "Kernel: rbf, Test Accuracy: 0.9770833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       248\n",
      "           1       0.96      0.99      0.98       232\n",
      "\n",
      "    accuracy                           0.98       480\n",
      "   macro avg       0.98      0.98      0.98       480\n",
      "weighted avg       0.98      0.98      0.98       480\n",
      "\n",
      "Kernel: sigmoid, Validation Accuracy: 0.9354166666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       250\n",
      "           1       0.92      0.94      0.93       230\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.94      0.94      0.94       480\n",
      "weighted avg       0.94      0.94      0.94       480\n",
      "\n",
      "Kernel: sigmoid, Test Accuracy: 0.9333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       248\n",
      "           1       0.93      0.93      0.93       232\n",
      "\n",
      "    accuracy                           0.93       480\n",
      "   macro avg       0.93      0.93      0.93       480\n",
      "weighted avg       0.93      0.93      0.93       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_svm_with_pca(kernel_type, n_components=0.95):\n",
    "    pipeline = Pipeline([\n",
    "        ('pca', PCA(n_components=n_components)),\n",
    "        ('svm', SVC(kernel=kernel_type))\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction\n",
    "\n",
    "    y_pred_val = pipeline.predict(X_val)\n",
    "    print(f\"Kernel: {kernel_type}, Validation Accuracy: {accuracy_score(y_val, y_pred_val)}\")\n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    print(f\"Kernel: {kernel_type}, Test Accuracy: {accuracy_score(y_test, y_pred_test)}\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    evaluate_svm_with_pca(kernel_type=kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear kernel:\n",
    "\n",
    "    Precision: 96.25% on both the validation and test set.\n",
    "    Precision and recall are almost identical for both classes, indicating that the model is well balanced.\n",
    "\n",
    "Polynomial kernel (degree=3):\n",
    "\n",
    "    Precision: An impressive 97.71% on both sets.\n",
    "    Precision and recall are higher than that of the linear kernel, especially notable is the improvement in the accuracy of class 1 detection.\n",
    "\n",
    "RBF kernel:\n",
    "\n",
    "    Precision: 97.50% on the validation set and 97.71% on the test set, which is one of the best results.\n",
    "    Precision and recall show outstanding performance, especially in terms of identification and error minimization for both classes.\n",
    "\n",
    "Sigmoidal kernel:\n",
    "\n",
    "    Precision: Lower than the other kernels, being 93.54% and 93.33% on the validation and test set, respectively.\n",
    "    Precision and recall are slightly lower, which may indicate less stability or generalization ability for more complex data splits.\n",
    "\n",
    "Overall analysis and recommendations:\n",
    "\n",
    "    Kernel selection: Polynomial and RBF kernels performed better, making them the preferred options for further use in the case of this dataset. They provide better class separation and can handle non-linearities in the data better. It also helps to reduce the dimensionality of the data while retaining the important features, which improves the classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with LLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear, Validation Accuracy: 0.9583333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       250\n",
      "           1       0.93      0.99      0.96       230\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "Kernel: linear, Test Accuracy: 0.9645833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       248\n",
      "           1       0.94      0.99      0.96       232\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.97      0.97      0.96       480\n",
      "weighted avg       0.97      0.96      0.96       480\n",
      "\n",
      "Kernel: poly, Validation Accuracy: 0.9604166666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       250\n",
      "           1       0.96      0.96      0.96       230\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "Kernel: poly, Test Accuracy: 0.9416666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       248\n",
      "           1       0.96      0.92      0.94       232\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.94      0.94      0.94       480\n",
      "weighted avg       0.94      0.94      0.94       480\n",
      "\n",
      "Kernel: rbf, Validation Accuracy: 0.9625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       250\n",
      "           1       0.94      0.99      0.96       230\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "Kernel: rbf, Test Accuracy: 0.9604166666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       248\n",
      "           1       0.94      0.98      0.96       232\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "Kernel: sigmoid, Validation Accuracy: 0.9145833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       250\n",
      "           1       0.91      0.91      0.91       230\n",
      "\n",
      "    accuracy                           0.91       480\n",
      "   macro avg       0.91      0.91      0.91       480\n",
      "weighted avg       0.91      0.91      0.91       480\n",
      "\n",
      "Kernel: sigmoid, Test Accuracy: 0.9208333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       248\n",
      "           1       0.92      0.92      0.92       232\n",
      "\n",
      "    accuracy                           0.92       480\n",
      "   macro avg       0.92      0.92      0.92       480\n",
      "weighted avg       0.92      0.92      0.92       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_svm_with_lle(kernel_type, n_neighbors=10, n_components=2):\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('lle', LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=n_components, method='standard', random_state=42)),\n",
    "        ('svm', SVC(kernel=kernel_type))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred_val = pipeline.predict(X_val)\n",
    "    print(f\"Kernel: {kernel_type}, Validation Accuracy: {accuracy_score(y_val, y_pred_val)}\")\n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    print(f\"Kernel: {kernel_type}, Test Accuracy: {accuracy_score(y_test, y_pred_test)}\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    evaluate_svm_with_lle(kernel_type=kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results Overview:\n",
    "\n",
    "    The linear kernel showed very good performance with accuracy above 96% on both datasets. This indicates that the linear model combined with LLE separates classes effectively.\n",
    "    The polynomial kernel also showed high accuracy on the validation set, but slightly decreased on the test set, which may indicate slight overtraining or sensitivity to changes in the data.\n",
    "    The RBF kernel showed stable and high results similar to the linear kernel, making it an excellent choice for this classification approach.\n",
    "    The sigmoidal kernel has the lowest accuracy among the kernels considered, but still achieves over 91% on both datasets. This is worse than the other kernels, but still shows good performance.\n",
    "\n",
    "Performance Analysis:\n",
    "\n",
    "    Precision and recall are high for almost all kernels, especially for linear and RBF. This indicates good classification quality, balanced distribution of type I and type II errors.\n",
    "    Polynomial and RBF kernels showed the best results for the combination of all metrics, which may be due to their ability to adapt to nonlinear data structures, which are better detected after applying LLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian model with  LLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with LLE on Validation set: 0.9625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       250\n",
      "           1       0.93      1.00      0.96       230\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "Accuracy with LLE on Test set: 0.9645833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       248\n",
      "           1       0.94      0.99      0.96       232\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.97      0.97      0.96       480\n",
      "weighted avg       0.97      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('lle', LocallyLinearEmbedding(n_neighbors=10, n_components=2, method='standard', random_state=42)),\n",
    "    ('nb', GaussianNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "print(\"Accuracy with LLE on Validation set:\", accuracy_score(y_val, y_pred_val))\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "# Prediction\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "print(\"Accuracy with LLE on Test set:\", accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of results:\n",
    "Validation set:\n",
    "\n",
    "    Accuracy: 96.25%. This result indicates the effectiveness of the combination of LLE and naive Bayes in class separation in the modified space.\n",
    "    Precision and Recall:\n",
    "        Class 0: Perfect precision (100%) and high recall (93%). This indicates that the model perfectly classifies Class 0 examples, with almost no Type I errors.\n",
    "        Class 1: Perfect precision (93%) and perfect recall (100%). Despite the small number of Type II errors for Class 1, the model hardly misses any examples of this class.\n",
    "\n",
    "Test Set:\n",
    "\n",
    "    Precision: 96.46%. This demonstrates the high generalizability of the model and the stability of the results between the validation and test sets.\n",
    "    Precision and Recall:\n",
    "        Class 0: Very high precision (99%) and excellent recall (94%). The model retains its ability to effectively recognize class 0 on the test set.\n",
    "        Class 1: Excellent precision (94%) and near perfect recall (99%). The model effectively minimizes type I errors by successfully classifying most of the class 1 examples.\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "    The use of LLE helps improve naive Bayesian performance, probably by better accounting for local data structures, which reduces the impact of the feature independence assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LDA with PCA on Validation set: 0.9666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       250\n",
      "           1       0.95      0.99      0.97       230\n",
      "\n",
      "    accuracy                           0.97       480\n",
      "   macro avg       0.97      0.97      0.97       480\n",
      "weighted avg       0.97      0.97      0.97       480\n",
      "\n",
      "Accuracy LDA with PCA on Test set: 0.9729166666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       248\n",
      "           1       0.96      0.99      0.97       232\n",
      "\n",
      "    accuracy                           0.97       480\n",
      "   macro avg       0.97      0.97      0.97       480\n",
      "weighted avg       0.97      0.97      0.97       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train_pca, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_val = lda.predict(X_val_pca)\n",
    "print(\"Accuracy LDA with PCA on Validation set:\", accuracy_score(y_val, y_pred_val))\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = lda.predict(X_test_pca)\n",
    "print(\"Accuracy LDA with PCA on Test set:\", accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a combination of PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis) for classification shows outstanding results on validation and test datasets. This combination of dimensionality reduction and classification techniques shows high efficiency in data processing.\n",
    "Results on the validation set:\n",
    "\n",
    "    Accuracy: 96.67%. This indicates that LDA after applying PCA performs well in class separation on the validation set.\n",
    "    Precision and Recall:\n",
    "        Class 0: Highest precision (99%) and excellent recall (95%), indicating that the model effectively identifies this class with minimal false positives.\n",
    "        Class 1: Excellent precision (95%) and near-perfect recall (99%), confirming the model's ability to reliably classify instances of this class while rarely missing true positive cases.\n",
    "\n",
    "Results on the test set:\n",
    "\n",
    "    Accuracy: 97.29%. This improvement over the validation set confirms the stability and generalization ability of the model.\n",
    "    Precision and Recall:\n",
    "        Class 0: Precision (99%) and recall (96%) remain high, demonstrating the model's robustness to changes in the test data.\n",
    "        Class 1: Precision (96%) and recall (99%) are again high, emphasizing the reliability of the model in recognizing this class.\n",
    "\n",
    "Analysis:\n",
    "\n",
    "    Benefits of PCA: Data preprocessing with PCA improves the quality of input data for LDA by reducing noise and highlighting the most relevant features, which improves classification performance.\n",
    "    Effectiveness of LDA: LDA effectively uses reduced data to maximize the differences between classes, as evidenced by high accuracy, precision and recall rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA with LLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LDA with LLE on Validation set: 0.95625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       250\n",
      "           1       0.93      0.98      0.96       230\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "Accuracy LDA with LLE on Test set: 0.9625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       248\n",
      "           1       0.94      0.99      0.96       232\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lle = LocallyLinearEmbedding(n_neighbors=10, n_components=2, method='standard', random_state=42)\n",
    "X_train_lle = lle.fit_transform(X_train)\n",
    "X_val_lle = lle.transform(X_val)\n",
    "X_test_lle = lle.transform(X_test)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train_lle, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_val = lda.predict(X_val_lle)\n",
    "print(\"Accuracy LDA with LLE on Validation set:\", accuracy_score(y_val, y_pred_val))\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "y_pred_test = lda.predict(X_test_lle)\n",
    "print(\"Accuracy LDA with LLE on Test set:\", accuracy_score(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of results:\n",
    "On validation set:\n",
    "\n",
    "    Accuracy: 95.625%. This result confirms the effectiveness of LLE combined with LDA for dimensionality reduction and subsequent data classification.\n",
    "    Precision and Recall:\n",
    "        Class 0: Very high precision (98%) and impressive recall (93%), indicating that the model is very accurate for this class with minimal false positives.\n",
    "        Class 1: Also excellent results with precision (93%) and very high recall (98%), indicating the model's high ability to correctly classify examples of this class with almost no true positive cases missed.\n",
    "\n",
    "On the test set:\n",
    "\n",
    "    Accuracy: 96.25%. The improvement in accuracy over the validation set shows that the model generalizes well to the data, presenting stable results.\n",
    "    Precision and Recall:\n",
    "        Class 0: High precision (99%) and excellent recall (94%), which supports the validation test results and indicates the model's robust ability to identify this class.\n",
    "        Class 1: Again high precision (94%) and near perfect recall (99%), confirming the strong ability of the model to classify with minimal errors.\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "    Application of LLE and LDA: Effective for this dataset, leading to high precision and a balance between precision and recall. This emphasizes that dimensionality reduction techniques can significantly improve the performance of classification models, especially when the data has a complex structure.\n",
    "    Generalizability: High accuracy on the test set confirms that the model is not overtrained and performs well on independent data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results have been saved in 'result.csv'.\n"
     ]
    }
   ],
   "source": [
    "eval_data = pd.read_csv('evaluate.csv')\n",
    "\n",
    "X_eval = eval_data.drop('ID', axis=1).values\n",
    "ids = eval_data['ID']\n",
    "\n",
    "# Pixel data normalization\n",
    "X_eval = X_eval / 255.0\n",
    "\n",
    "pca = PCA(n_components=108)\n",
    "X_eval_pca = pca.fit_transform(X_eval)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train_pca, y_train)\n",
    "\n",
    "predictions = lda.predict(X_eval_pca)\n",
    "\n",
    "result_df = pd.DataFrame({'ID': ids, 'label': predictions})\n",
    "result_df.to_csv('result.csv', index=False)\n",
    "\n",
    "print(\"The results have been saved in 'result.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
